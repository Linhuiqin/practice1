{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1e7918-3a44-4d3d-b674-896da8303e4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'scrapy也是个python第三方库，是个网络爬虫框架 pip install scrapy\\n安装后可用scrapy -h测试安装效果\\n注意，scrapy不是一个简单的函数功能库，而是一个爬虫框架。是实现爬虫功能的一个软件\\n结构和功能组件集合。爬虫框架是一个半成品，能够帮助用户实现专业网络爬虫。\\n数据路径\\n1）URL请求通过spider到达engine，engine将这个爬虫请求转发给scheduler模块（负责对爬取请求进行调度）\\n2）从scheduler模块通过engine模块到达downloader模块，且最终数据返回到spider模块\\n3）从spider到engine，再到item pipelines模块以及scheduler模块\\n（spider处理从down loader获得的响应，也就是从网络中爬取的相关内容，处理后产生两个数据\\n类型，爬取项scrapy item和一个新的爬取请求，将他们发送给engine模块，engine将item发送给\\nitem pipelines模块，把request发送给scheduler进行调度，从而为后期的数据处理，以及再次\\n启动网络爬虫请求提供新的数据来源。\\nengine控制着各个模块的数据流，且不断从scheduler获得真实要爬取的请求。整个框架的执行，是从\\n向engine发送第一个请求开始，到获得所有链接内容，并将内容处理后放到item pipelines为止。\\n所以说，这个框架的入口是spiders，出口是item pipelines）\\n用户需编写spider和item模块，spider提供整个框架爬取需要的URL链接，同时解析从网络上\\n获得的页面内容，item负责对提取的信息进行后处理。把这种代码编写方式称为配置。'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''scrapy也是个python第三方库，是个网络爬虫框架 pip install scrapy\n",
    "安装后可用scrapy -h测试安装效果\n",
    "注意，scrapy不是一个简单的函数功能库，而是一个爬虫框架。是实现爬虫功能的一个软件\n",
    "结构和功能组件集合。爬虫框架是一个半成品，能够帮助用户实现专业网络爬虫。\n",
    "数据路径\n",
    "1）URL请求通过spider到达engine，engine将这个爬虫请求转发给scheduler模块（负责对爬取请求进行调度）\n",
    "2）从scheduler模块通过engine模块到达downloader模块，且最终数据返回到spider模块\n",
    "3）从spider到engine，再到item pipelines模块以及scheduler模块\n",
    "（spider处理从down loader获得的响应，也就是从网络中爬取的相关内容，处理后产生两个数据\n",
    "类型，爬取项scrapy item和一个新的爬取请求，将他们发送给engine模块，engine将item发送给\n",
    "item pipelines模块，把request发送给scheduler进行调度，从而为后期的数据处理，以及再次\n",
    "启动网络爬虫请求提供新的数据来源。\n",
    "engine控制着各个模块的数据流，且不断从scheduler获得真实要爬取的请求。整个框架的执行，是从\n",
    "向engine发送第一个请求开始，到获得所有链接内容，并将内容处理后放到item pipelines为止。\n",
    "所以说，这个框架的入口是spiders，出口是item pipelines）\n",
    "用户需编写spider和item模块，spider提供整个框架爬取需要的URL链接，同时解析从网络上\n",
    "获得的页面内容，item负责对提取的信息进行后处理。把这种代码编写方式称为配置。'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075970dd-a2f6-4ecc-ba5f-c22aa39305c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#股票数据scrapy爬虫练习\n",
    "#建立工程和生成spider模块；编写spider；编写item \n",
    "'''命令行（scrapy startproject BaiduStocks）新建一个baidustocks目录，(cd BaiduStocks)在该目录下生成一个爬虫，\n",
    "用genspider生成一个叫stocks的爬虫(scrapy genspider stocks baidu.com)\n",
    "进一步修改spiders/stocks.py文件\n",
    "编写的配置stocks.py文件--处理所有股票信息，并且把提取的信息以字典类型封装成item类，给到了后面的pipeline'''\n",
    "#获取股票列表-东方财富网-http://quote.eastmoney.com/stocklist.html\n",
    "#获取个股信息=百度股票-https://gupiao.baidu.com/stock/\n",
    "#单个股票-https://gupiao.baidu.com/stock/sz002439.html\n",
    "'''配置pipelines.py文件，定义对爬取项scraped item的处理类'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf82948-39f7-4778-9b36-58bf5826d168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapy爬取天气\n",
    "#打开终端cd （xiaoyupractice，然后scrapy startproject TianqiScrapy，生成文件夹\n",
    "#可用命令行或者直接手动在spider文件夹里新建一个自己的爬虫.py文件，我把它命名为tianqiSpider\n",
    "#这里面就是主要的爬虫程序，需编写一下\n",
    "#然后在TianqiScrapy文件夹下新建一个run.py文件，用于运行\n",
    "%load run.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777432a-63ee-4702-befc-f8270bf4e9f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
