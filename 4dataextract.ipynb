{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e5a5b9-a83d-4d6d-8d7a-e2213df5dad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#信息标记的三种形式\n",
    "'''html通过预定义的<>...</>标签形式组织不同类型的信息\n",
    "国际公认的信息标记种类三种-xml,json,yaml\n",
    "xml扩展标记语言，用尖括号和标签标记信息的表达方式\n",
    "json有类型的键值对构建的信息表达方式，字符串必须用双引号\n",
    "一个键对应多个值时，用方括号\n",
    "yaml递归，无类型键值对'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b33155-9aa5-4bc5-bd15-0725177c09aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#html信息提取，提取html中所欲的URL链接\n",
    "#<>.find_all(name,attrs,recursive,string,**kwargs)\n",
    "#返回一个列表类型，存储查找的结果\n",
    "#由于find_all非常常用，可以简写直接省略掉\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17b0a61f-14f7-4085-9a64-1da2566a4e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    排名    \t    学校    \t   总分    \t\n",
      "    1     \t 清华大学 \t  1004.1  \t\n",
      "    2     \t 北京大学 \t  910.5   \t\n",
      "    3     \t 浙江大学 \t  822.9   \t\n",
      "    4     \t上海交通大学\t  778.6   \t\n",
      "    5     \t 复旦大学 \t  712.4   \t\n",
      "    6     \t 南京大学 \t  676.2   \t\n",
      "    7     \t中国科学技术大学\t  608.6   \t\n",
      "    8     \t华中科技大学\t  606.2   \t\n",
      "    9     \t 武汉大学 \t  599.1   \t\n",
      "    10    \t西安交通大学\t  572.6   \t\n",
      "    11    \t 中山大学 \t  570.0   \t\n",
      "    12    \t 四川大学 \t  546.9   \t\n",
      "    13    \t哈尔滨工业大学\t  544.2   \t\n",
      "    14    \t北京航空航天大学\t  543.5   \t\n",
      "    15    \t 东南大学 \t  532.3   \t\n",
      "    16    \t北京理工大学\t  529.3   \t\n",
      "    17    \t 同济大学 \t  527.0   \t\n",
      "    18    \t中国人民大学\t  526.3   \t\n",
      "    19    \t北京师范大学\t  523.4   \t\n",
      "    20    \t 南开大学 \t  490.4   \t\n",
      "    21    \t 天津大学 \t  480.5   \t\n",
      "    22    \t 山东大学 \t  472.8   \t\n",
      "    23    \t 中南大学 \t  466.1   \t\n",
      "    24    \t 厦门大学 \t  463.2   \t\n",
      "    25    \t西北工业大学\t  462.0   \t\n",
      "    26    \t华南理工大学\t  444.2   \t\n",
      "    27    \t 吉林大学 \t  439.1   \t\n",
      "    28    \t电子科技大学\t  437.0   \t\n",
      "    29    \t 湖南大学 \t  435.5   \t\n",
      "    30    \t中国农业大学\t  432.8   \t\n"
     ]
    }
   ],
   "source": [
    "#中国大学排名爬虫练习 简化版本\n",
    "#每个div标签包含了所有大学数据，每个td和a中信息又被div标签包围，\n",
    "#所以要在整个html文件中，先找到div标签，获取所有大学的相关信息，\n",
    "#然后在div标签中解析td和a标签，获得每一个大学的信息，再把\n",
    "#大学相关数据写到ulist列表中\n",
    "import requests,bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ulist=[]#定义列表一会用于存放爬取的内容\n",
    "r=requests.get('https://www.shanghairanking.cn/rankings/bcur/2023',headers={'user-agent':'Mozilla/5.0'},timeout=30)\n",
    "#print(r.status_code)#检验状态码\n",
    "r.raise_for_status()#这个也是检验状态码的，返回的是none\n",
    "r.encoding=r.apparent_encoding#定义编码为utf-8\n",
    "i=0\n",
    "soup=BeautifulSoup(r.text,\"html.parser\")#把前面获取的html文件定义为soup文件\n",
    "#print(soup.find_all('a'))#找出所有a标签的内容\n",
    "#我发现的逻辑是，div标签下的td标签有排名和总分，div标签下的a标签是学校名称\n",
    "for a in soup.find('div').children:#实际发现代码没有循环遍历，查找div标签的子类\n",
    "#  if isinstance(a,bs4.element.Tag):\n",
    "    tds=a('td')#div标签子类里查找td标签\n",
    "#    for m in range(180):\n",
    "#      print(tds[m].string,'这是第',m,'个内容')\n",
    "    a_s=a('a')#div标签子类里查找a标签\n",
    "#    for m in range(68):\n",
    "#      print(a_s[m].string,'这是第',m,'个内容')\n",
    "    for i in range(30):\n",
    "      ulist.append([tds[0+i*6].string.strip(),a_s[9+i*2].string.strip(),tds[4+i*6].string.strip()])\n",
    "#    print(ulist)\n",
    "    \n",
    "print(\"{:^10}\\t{:^10}\\t{:^9}\\t\".format(\"排名\",\"学校\",\"总分\"))\n",
    "for i in range(30):\n",
    "    print(\"{:^10}\\t{:^6}\\t{:^10}\\t\".format(ulist[i][0],ulist[i][1],ulist[i][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93596430-3f83-4b4b-9552-b4e9d49c8e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    排名    \t    学校    \t   总分    \t\n",
      "    1     \t 清华大学 \t  1004.1  \t\n",
      "    2     \t 北京大学 \t  910.5   \t\n",
      "    3     \t 浙江大学 \t  822.9   \t\n",
      "    4     \t上海交通大学\t  778.6   \t\n",
      "    5     \t 复旦大学 \t  712.4   \t\n",
      "    6     \t 南京大学 \t  676.2   \t\n",
      "    7     \t中国科学技术大学\t  608.6   \t\n",
      "    8     \t华中科技大学\t  606.2   \t\n",
      "    9     \t 武汉大学 \t  599.1   \t\n",
      "    10    \t西安交通大学\t  572.6   \t\n",
      "    11    \t 中山大学 \t  570.0   \t\n",
      "    12    \t 四川大学 \t  546.9   \t\n",
      "    13    \t哈尔滨工业大学\t  544.2   \t\n",
      "    14    \t北京航空航天大学\t  543.5   \t\n",
      "    15    \t 东南大学 \t  532.3   \t\n",
      "    16    \t北京理工大学\t  529.3   \t\n",
      "    17    \t 同济大学 \t  527.0   \t\n",
      "    18    \t中国人民大学\t  526.3   \t\n",
      "    19    \t北京师范大学\t  523.4   \t\n",
      "    20    \t 南开大学 \t  490.4   \t\n",
      "    21    \t 天津大学 \t  480.5   \t\n",
      "    22    \t 山东大学 \t  472.8   \t\n",
      "    23    \t 中南大学 \t  466.1   \t\n",
      "    24    \t 厦门大学 \t  463.2   \t\n",
      "    25    \t西北工业大学\t  462.0   \t\n",
      "    26    \t华南理工大学\t  444.2   \t\n",
      "    27    \t 吉林大学 \t  439.1   \t\n",
      "    28    \t电子科技大学\t  437.0   \t\n",
      "    29    \t 湖南大学 \t  435.5   \t\n",
      "    30    \t中国农业大学\t  432.8   \t\n"
     ]
    }
   ],
   "source": [
    "#中国大学排名爬虫练习 优化版本\n",
    "import requests,bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def catchsomething(url):#爬取网页，返回html\n",
    "    try:\n",
    "        r=requests.get(url,headers={'user-agent':'Mozilla/5.0'},timeout=30)\n",
    "        r.raise_for_status()#这个也是检验状态码的，返回的是none\n",
    "        r.encoding=r.apparent_encoding#定义编码为utf-8\n",
    "        return r.text\n",
    "    except:\n",
    "        return '获取失败'\n",
    "\n",
    "    \n",
    "def filllist(html,ulist):#获得html内的需要内容，并存放在列表中\n",
    "    i=0\n",
    "    soup=BeautifulSoup(html,\"html.parser\")#把前面获取的html文件定义为soup文件\n",
    "    for a in soup.find('div').children:#实际发现代码没有循环遍历，查找div标签的子类\n",
    "        if isinstance(a,bs4.element.Tag):\n",
    "            tds=a('td')#div标签子类里查找td标签\n",
    "            a_s=a('a')#div标签子类里查找a标签\n",
    "            for i in range(30):\n",
    "                ulist.append([tds[0+i*6].string.strip(),a_s[9+i*2].string.strip(),tds[4+i*6].string.strip()])\n",
    "\n",
    "\n",
    "def printlist(ulist):#从给定的列表中打印出内容\n",
    "    i=0\n",
    "    print(\"{:^10}\\t{:^10}\\t{:^9}\\t\".format(\"排名\",\"学校\",\"总分\"))\n",
    "    for i in range(30):\n",
    "        print(\"{:^10}\\t{:^6}\\t{:^10}\\t\".format(ulist[i][0],ulist[i][1],ulist[i][2]))\n",
    "\n",
    "        \n",
    "def main():\n",
    "    univlist=[]#定义列表一会用于存放爬取的内容\n",
    "    url='https://www.shanghairanking.cn/rankings/bcur/2023'\n",
    "    uhtml=catchsomething(url)\n",
    "    filllist(uhtml,univlist)\n",
    "    printlist(univlist)\n",
    "\n",
    "    \n",
    "main()\n",
    "#小结：挺完美的。需优化部分1）只能爬取前30个，后面爬取不到，会报错。可以设置一个输入框，\n",
    "#超过30则返回请输入30一下整数；2）所有的数据是存放在同一个网页中，但是后面页面应该是被\n",
    "#动态封装起来了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ff6b828-530e-43e7-9e99-1ba47db0ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{return {data:[{year:aN,rankId:aO,bcurTypes:[{id:aO,nameCn:eb,nameShort:\"主榜\",versions:\"2023,2022,2021,2020,2019,2018,2017,2016,2015\",isNew:b},{id:21,nameCn:\"中国医药类大学排名\",nameShort:\"医药\",versions:\"2023,2022,2021,2020,2019\",isNew:b},{id:22,nameCn:\"中国财经类大学排名\",nameShort:\"财经\",versions:R,isNew:b},{id:23,nameCn:\"中国语言类大学排名\",nameShort:\"语言\",versions:R,isNew:b},{id:25,nameCn:\"中国政法类大学排名\",nameShort:\"政法\",versions:R,isNew:b},{id:24,nameCn:\"中国民族类大学排名\",nameShort:\"民族\",versions:R,isNew:b},{id:26,nameCn:\"中国体育类大学排名\",nameShort:\"体育\",versions:R,isNew:b},{id:aP,nameCn:\"中国合作办学大学排名\",nameShort:\"合作\",versions:R,isNew:b},{id:aQ,nameCn:\"中国大学排名（总榜）\",nameShort:\"总榜\",versions:R,isNew:b},{id:aR,nameCn:\"中国民办高校排名（主榜）\",nameShort:\"民办主榜\",versions:at,isNew:b},{id:ec,nameCn:\"中国民办财经类高校排名\",nameShort:\"民办财经\",versions:at,isNew:b},{id:ed,nameCn:\"中国民办语言类高校排名\",nameShort:\"民办语言\",versions:at,isNew:b},{id:-15,nameCn:\"中国民办高校排名（总榜）\",nameShort:\"民办总榜\",versions:at,isNew:b},{id:30,nameCn:\"中国艺术类高校名单\",nameShort:\"艺术\",versions:R,isNew:b}],introWeb:\"“软科中\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 2 (char 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m#print(type(data),data[:11000])\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(result[:\u001b[38;5;241m1000\u001b[39m])\n\u001b[0;32m---> 15\u001b[0m result\u001b[38;5;241m=\u001b[39m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(result))\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/json/decoder.py:353\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[38;5;124;03m\"\"\"Decode a JSON document from ``s`` (a ``str`` beginning with\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03ma JSON document) and return a 2-tuple of the Python\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03mrepresentation and the index in ``s`` where the document ended.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    350\u001b[0m \n\u001b[1;32m    351\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscan_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 2 (char 1)"
     ]
    }
   ],
   "source": [
    "#获取高校大学所有排名\n",
    "'''该链接一共含有20页，每页30个高校信息，一共590个高校信息\n",
    "单纯用request和beautifulsoup只能抓取第一面的30个高校类型（静态抓取不能实现）'''\n",
    "\n",
    "import requests,json\n",
    "\n",
    "url='https://www.shanghairanking.cn/_nuxt/static/1692115442/rankings/bcur/2023/payload.js'\n",
    "r=requests.get(url)\n",
    "r.encoding=r.apparent_encoding\n",
    "data=str(r.text)\n",
    "#print(type(data),data[:11000])\n",
    "\n",
    "\n",
    "print(result[:1000])\n",
    "result=json.loads(result)\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f2b7549-8c2b-4b8e-9eeb-2bcdef9f31b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "#淘宝商品定向爬虫练习\n",
    "#提交商品搜索请求，循环获取页面；对每个页面，提取商品名称和价格信息；将信息输出到屏幕上\n",
    "#q=比基尼\n",
    "#如果在elements元素选项卡中拿不到数据（即elements中可以搜到，但是用bs获取为空），说明该资源是在请求服务器时动态查到页面的。\n",
    "#一般而言所有在页面中显示出来的数据都会加载到network选项卡中，因此在network中搜索，快速定位到数据所在的response文件\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url='https://s.taobao.com/search?commend=all&ie=utf8&initiative_id=tbindexz_20170306&q=比基尼&search_type=item&sourceId=tb.index&spm=a21bo.jianhua.201856-taobao-item.2&ssid=s5-e'\n",
    "url_1='https://h5api.m.taobao.com'\n",
    "r=requests.get(url,headers={'user-agent':'Mozilla/5.0'})\n",
    "r.encoding=r.apparent_encoding\n",
    "#print(r.text)\n",
    "soup=BeautifulSoup(r.text,'html.parser')\n",
    "print(soup.find_all('span'))\n",
    "#淘宝页面内容获取不到 爬取淘宝应该是难度比较高的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7f0501-8237-4201-901e-893b49811b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#股票数据定向爬虫练习\n",
    "\n",
    "http://quote.eastmoney.com/center/gridlist.html#hs_a_board\n",
    "http://quote.eastmoney.com/center/gridlist.html#hs_a_board"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
